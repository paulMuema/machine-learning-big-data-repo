{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4evk78aMDwycovmpa6lSr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Using TensorFlow and Keras for Transfer Learning"
      ],
      "metadata": {
        "id": "LbCBDr5fGsca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Libraries and load a pre-trained model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import os"
      ],
      "metadata": {
        "id": "sONm4OZPGybX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load a model like VGG16 (Without the final classification layer) to use it as a feature extractor."
      ],
      "metadata": {
        "id": "5b7fDddRHNrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the pre-trained model without the top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nywXxVZHbg2",
        "outputId": "6ea833cf-d458-4320-fd99-3355a59bf2cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freezing layers ensures they are not trained during the initial fine-tuning process."
      ],
      "metadata": {
        "id": "sDn8ZAjTHs0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Freeze the Base Model Layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "meRPQcGMH33G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add custom dense layers to adapt the pre-trained model for the new classification task."
      ],
      "metadata": {
        "id": "2j9rOAsaIAuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add custom layers for the target task\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x) #for binary classification\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "#Ensure input shape matched your data generator's output\n",
        "\n",
        "input_shape = (224, 224, 3) #Assuming you're using RGB images\n",
        "model.build(input_shape = (None, *input_shape)) #Build the model with an explicit input shape"
      ],
      "metadata": {
        "id": "ZQTWjQg0IJBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose a lower learning rate to preserve the pre-trained weights and compile the model."
      ],
      "metadata": {
        "id": "dwpg-voqJHfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "bEi2-Iq4JubJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train') #training data directory\n",
        "validation_dir = os.path.join(PATH, 'validation') #validation data directory\n",
        "\n",
        "#BATCH_SIZE = 32\n",
        "#IMG_SIZE = (160, 160)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLRqNqNOMXhB",
        "outputId": "aa7d6cf8-ed2f-477f-fe17-4c55e3bcb03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "\u001b[1m68606236/68606236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load training and validation data\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir, #Replace with the path to your training data directory\n",
        "    target_size=(160, 160), #Adjust if needed\n",
        "    batch_size=32, #Adjust if needed\n",
        "    class_mode='binary') #Use categorical\n",
        "val_data = val_datagen.flow_from_directory(\n",
        "    validation_dir, #Replace with the path to your validation data directory\n",
        "    target_size=(160, 160), #Adjust if needed\n",
        "    batch_size=32, #Adjust if needed\n",
        "    class_mode='binary') #Use categorical"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMAdK5-HPgPC",
        "outputId": "c45e56d8-306e-430c-85ca-0d0a75d81747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model\n",
        "history = model.fit(train_data, epochs=5, validation_data=val_data)"
      ],
      "metadata": {
        "id": "AhFhWdfbMzTX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}